{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # version '0.18.1'\n",
    "import numpy as np # version '1.10.4'\n",
    "import matplotlib.pyplot as plt # version '2.1.0'\n",
    "import ast\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal of this notebook\n",
    "\n",
    "- For each 311 point, identify if there is an AHV near it. Add a column that says AHV = 1 or 0 in the 311 dataset\n",
    "\n",
    "# Methodology\n",
    "\n",
    "- This is equivalent of trying to do the buffer and intersect function on arcGIS\n",
    "- The goal now is to get both AHV and 311 dataset to the same time period so that the spatial intersection can be conducted\n",
    "- The test run now will only focus on the year of 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AHV\n",
    "\n",
    "After much trial and error, we finally figured out that AHV dataset has a delayed data update, ie. those that are recently uploaded belongs to a few months back. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahv = pd.read_csv('ahv_lat_long.csv')\n",
    "ahv['timestamp'] = pd.to_datetime(ahv['timestamp'])\n",
    "ahv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with the range column of AHV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code credit: the genius duke\n",
    "def correct_json(s):\n",
    "    '''\n",
    "    This function removes the extra characters from the json for permitted times and helps us read the values easily.\n",
    "    '''\n",
    "    s = re.sub(\"-\\d\\d:\\d\\d\",\"'\", s)\n",
    "    s = s.replace(\"start': \", \"start': '\")    \n",
    "    s = s.replace(\"end': \", \"end': '\")        \n",
    "    s = s.replace(\"u'\", \"'\")    \n",
    "    return s\n",
    "\n",
    "ahv['range_json'] = ahv['range'].apply(correct_json)\n",
    "ahv[['timestamp','range_json', 'range']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetime adjustments\n",
    "\n",
    "The timestamp seems IS NOT a good ballpark of the start dates in the range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahv['ballpark_time'] = pd.to_datetime(ahv.timestamp, utc=True)\n",
    "ahv['ballpark_year'] = ahv['ballpark_time'].dt.year\n",
    "ahv['ballpark_month'] = ahv['ballpark_time'].dt.month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahv_2016 = ahv[(ahv['ballpark_year']== 2016)]\n",
    "ahv_2015_11 = ahv[(ahv['ballpark_year']== 2015)&(ahv['ballpark_month']==11)]\n",
    "ahv_2015_12 = ahv[(ahv['ballpark_year']== 2015)&(ahv['ballpark_month']==12)]\n",
    "ahv_2017_01 = ahv[(ahv['ballpark_year']== 2017)&(ahv['ballpark_month']==1)]\n",
    "ahv_2017_02 = ahv[(ahv['ballpark_year']== 2017)&(ahv['ballpark_month']==2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahv_2016_final = ahv_2015_11.append(ahv_2015_12).append(ahv_2016).append(ahv_2017_01).append(ahv_2017_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (ahv_2016_final.shape)\n",
    "ahv_2016_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 311 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Methodology\n",
    "\n",
    "### 1) Check if construction before or after hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints16= pd.read_csv('2016_dep_noise.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints16['c_date'] = pd.to_datetime(complaints16['Created Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (complaints16.shape)\n",
    "complaints16.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints16 = complaints16[complaints16.Descriptor.isin(['Noise: Construction Before/After Hours (NM1)',\n",
    "                              'Noise: Jack Hammering (NC2)','Noise: Construction Equipment (NC1)',\n",
    "                             'Noise: Manufacturing Noise (NK1)'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it takes too long to run the whole thing, will parallelize by splitting it up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) For each complaint, if it is within 200m of ahv, save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_dist(complaint_lat,complaint_lon,ahv_lat,ahv_lon):\n",
    "    ''' \n",
    "    This function returns the distance between two points\n",
    "    Input : Latitude1, Longitude1, Latitude2, Longitude2\n",
    "    Output : Distance in Metres\n",
    "    '''\n",
    "    from math import sin, cos, sqrt, atan2, radians\n",
    "   # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "    lat1 = radians(complaint_lat)\n",
    "    lon1 = radians(complaint_lon)\n",
    "    lat2 = radians(ahv_lat)\n",
    "    lon2 = radians(ahv_lon)\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return(distance*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahv_list = []\n",
    "\n",
    "def filterdistance(complaint, ahv_df):\n",
    "    ''' \n",
    "       This function returns the indexes of all the AHV permits\n",
    "       that the complaint lies within.\n",
    "       Input : Single complaint, dataframe of AHV permits\n",
    "       Output : AHV permit indexes\n",
    "       '''\n",
    "    for index,i in ahv_df.iterrows(): #for each ahv record\n",
    "        if return_dist(float(complaint.Latitude), float(complaint.Longitude), i.lon, i.lat)<200: #if distance is less than 200m\n",
    "            ahv_list.append(index)\n",
    "#             ahv_within_radius.append(list(i))\n",
    "\n",
    "    return (ahv_list)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_dist(float(-73.946165),float(40.77410), -73.946165, 40.77410)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints16[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahv_2016_final[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_time(complaint, ahv):\n",
    "    ''' \n",
    "    This function returns the indexes of all the AHV permits\n",
    "    that the complaint lies within.\n",
    "    Input : Single complaint, dataframe of AHV permits\n",
    "    Output : AHV permit indexes\n",
    "    '''\n",
    "    column_list = []\n",
    "    for index,k in ahv.iterrows():\n",
    "        for j in ast.literal_eval(k['range_json']):\n",
    "            if ((complaint.c_date>pd.to_datetime(j['start']))&(complaint.c_date<pd.to_datetime(j['end']))):\n",
    "                column_list.append(index)\n",
    "    return(column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints16['AHV'] = 0\n",
    "start= time.time()\n",
    "counter = 0\n",
    "for index,i in complaints16.iterrows():\n",
    "    time_indices = []\n",
    "    space_indices = []\n",
    "    time_indices = filtered_time(i,ahv_2016_final)\n",
    "    ahv_final = ahv_2016_final.ix[time_indices]\n",
    "    space_indices = filterdistance(i,ahv_final)\n",
    "    if len(space_indices)>0:\n",
    "        complaints16.AHV.loc[index] = 1\n",
    "    counter = counter + 1\n",
    "\n",
    "print(\"Time to run: {} seconds\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps: After getting AHV final, need to do another filterdistance with 311 dataset, this time using index,i of complaints so that we can get the 311 points of interest and record AHV=1 for these points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints16.to_csv('subset_files/ahv_1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PUI2016_Python3",
   "language": "python",
   "name": "pui2016_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
